{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-14T06:05:39.438828Z",
     "start_time": "2024-09-14T06:05:39.433827Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:05:39.968267Z",
     "start_time": "2024-09-14T06:05:39.929672Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv(\"data/exp_transfer_learning.csv\")",
   "id": "19dde0f7df392ea9",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:05:40.450108Z",
     "start_time": "2024-09-14T06:05:40.440109Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.dropna(subset=['text'])",
   "id": "2ba25b55d47daab3",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:05:40.928608Z",
     "start_time": "2024-09-14T06:05:40.888269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "# Step 3: Remove Special Characters\n",
    "def clean_text(text):\n",
    "    # Remove special characters (you can customize the regex as needed)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # You can also remove extra spaces or normalize spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function to the 'text' column\n",
    "df['text'] = df['text'].apply(clean_text)"
   ],
   "id": "b851226d1d1c72ac",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:05:41.362597Z",
     "start_time": "2024-09-14T06:05:41.353596Z"
    }
   },
   "cell_type": "code",
   "source": "df.head(5)",
   "id": "dd833ecc6f79492b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  dataset_name                                               text label_name  \\\n",
       "0       OLID19  USER She should ask a few native Americans wha...  subtask_a   \n",
       "1       OLID19  USER USER Go home youre drunk USER MAGA Trump2...  subtask_a   \n",
       "2       OLID19  Amazon is investigating Chinese employees who ...  subtask_a   \n",
       "3       OLID19  USER Someone shouldveTaken this piece of shit ...  subtask_a   \n",
       "4       OLID19  USER USER Obama wanted liberals amp illegals t...  subtask_a   \n",
       "\n",
       "  label_value                                   label_definition   source  \\\n",
       "0         OFF  Level A: Offensive language identification \\r\\...  Twitter   \n",
       "1         OFF  Level A: Offensive language identification \\r\\...  Twitter   \n",
       "2         NOT  Level A: Offensive language identification \\r\\...  Twitter   \n",
       "3         OFF  Level A: Offensive language identification \\r\\...  Twitter   \n",
       "4         NOT  Level A: Offensive language identification \\r\\...  Twitter   \n",
       "\n",
       "  language  \n",
       "0      eng  \n",
       "1      eng  \n",
       "2      eng  \n",
       "3      eng  \n",
       "4      eng  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>text</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label_value</th>\n",
       "      <th>label_definition</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>USER She should ask a few native Americans wha...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>OFF</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>USER USER Go home youre drunk USER MAGA Trump2...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>OFF</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>NOT</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>USER Someone shouldveTaken this piece of shit ...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>OFF</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>USER USER Obama wanted liberals amp illegals t...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>NOT</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:05:42.000853Z",
     "start_time": "2024-09-14T06:05:41.978336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_target = df[df[\"dataset_name\"] == \"EDOS\"].copy()\n",
    "df_target"
   ],
   "id": "1d817f876e0d46e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dataset_name, text, label_name, label_value, label_definition, source, language]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>text</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label_value</th>\n",
       "      <th>label_definition</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:05:43.332120Z",
     "start_time": "2024-09-14T06:05:43.292120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_target['label_value'] = df_target.apply(lambda row: 0 if row[\"label_value\"] == \"not sexist\" else 1, axis=1)\n",
    "df_target"
   ],
   "id": "6696627d6a8fecb6",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [34]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df_target[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel_value\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_target\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m row: \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel_value\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot sexist\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      2\u001B[0m df_target\n",
      "File \u001B[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3645\u001B[0m, in \u001B[0;36mDataFrame.__setitem__\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   3643\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setitem_array(key, value)\n\u001B[0;32m   3644\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, DataFrame):\n\u001B[1;32m-> 3645\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_item_frame_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3646\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m (\n\u001B[0;32m   3647\u001B[0m     is_list_like(value)\n\u001B[0;32m   3648\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mis_unique\n\u001B[0;32m   3649\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_indexer_for([key])) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(value)\n\u001B[0;32m   3650\u001B[0m ):\n\u001B[0;32m   3651\u001B[0m     \u001B[38;5;66;03m# Column to set is duplicated\u001B[39;00m\n\u001B[0;32m   3652\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setitem_array([key], value)\n",
      "File \u001B[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3775\u001B[0m, in \u001B[0;36mDataFrame._set_item_frame_value\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   3773\u001B[0m len_cols \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_scalar(cols) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(cols)\n\u001B[0;32m   3774\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m len_cols \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(value\u001B[38;5;241m.\u001B[39mcolumns):\n\u001B[1;32m-> 3775\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumns must be same length as key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   3777\u001B[0m \u001B[38;5;66;03m# align right-hand-side columns if self.columns\u001B[39;00m\n\u001B[0;32m   3778\u001B[0m \u001B[38;5;66;03m# is multi-index and self[key] is a sub-frame\u001B[39;00m\n\u001B[0;32m   3779\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns, MultiIndex) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[0;32m   3780\u001B[0m     loc, (\u001B[38;5;28mslice\u001B[39m, Series, np\u001B[38;5;241m.\u001B[39mndarray, Index)\n\u001B[0;32m   3781\u001B[0m ):\n",
      "\u001B[1;31mValueError\u001B[0m: Columns must be same length as key"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:05:46.381101Z",
     "start_time": "2024-09-14T06:05:46.368096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_aux = df[df[\"dataset_name\"] != \"EDOS\"].copy()\n",
    "df_aux"
   ],
   "id": "c1bd799ba96f476f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     dataset_name                                               text  \\\n",
       "0          OLID19  USER She should ask a few native Americans wha...   \n",
       "1          OLID19  USER USER Go home youre drunk USER MAGA Trump2...   \n",
       "2          OLID19  Amazon is investigating Chinese employees who ...   \n",
       "3          OLID19  USER Someone shouldveTaken this piece of shit ...   \n",
       "4          OLID19  USER USER Obama wanted liberals amp illegals t...   \n",
       "...           ...                                                ...   \n",
       "4199       OLID19  AfD Like a BOSS AfDOrdner reagiert COOL Antifa...   \n",
       "4200       OLID19  98 of all mass shootings occur in gun free zon...   \n",
       "4201       OLID19  USER USER USER USER USER USER Conservatives wh...   \n",
       "4202       OLID19  USER The washedout idiot Biden feels he has a ...   \n",
       "4203       OLID19                                          USER Fair   \n",
       "\n",
       "     label_name label_value  \\\n",
       "0     subtask_a         OFF   \n",
       "1     subtask_a         OFF   \n",
       "2     subtask_a         NOT   \n",
       "3     subtask_a         OFF   \n",
       "4     subtask_a         NOT   \n",
       "...         ...         ...   \n",
       "4199  subtask_a         NOT   \n",
       "4200  subtask_a         NOT   \n",
       "4201  subtask_a         NOT   \n",
       "4202  subtask_a         OFF   \n",
       "4203        NaN         NaN   \n",
       "\n",
       "                                       label_definition   source language  \n",
       "0     Level A: Offensive language identification \\r\\...  Twitter      eng  \n",
       "1     Level A: Offensive language identification \\r\\...  Twitter      eng  \n",
       "2     Level A: Offensive language identification \\r\\...  Twitter      eng  \n",
       "3     Level A: Offensive language identification \\r\\...  Twitter      eng  \n",
       "4     Level A: Offensive language identification \\r\\...  Twitter      eng  \n",
       "...                                                 ...      ...      ...  \n",
       "4199  Level A: Offensive language identification \\r\\...  Twitter      eng  \n",
       "4200  Level A: Offensive language identification \\r\\...  Twitter      eng  \n",
       "4201  Level A: Offensive language identification \\r\\...  Twitter      eng  \n",
       "4202  Level A: Offensive language identification \\r\\...  Twitter      eng  \n",
       "4203                                                NaN      NaN      NaN  \n",
       "\n",
       "[4204 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>text</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label_value</th>\n",
       "      <th>label_definition</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>USER She should ask a few native Americans wha...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>OFF</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>USER USER Go home youre drunk USER MAGA Trump2...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>OFF</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>NOT</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>USER Someone shouldveTaken this piece of shit ...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>OFF</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>USER USER Obama wanted liberals amp illegals t...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>NOT</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>AfD Like a BOSS AfDOrdner reagiert COOL Antifa...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>NOT</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>98 of all mass shootings occur in gun free zon...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>NOT</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>USER USER USER USER USER USER Conservatives wh...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>NOT</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4202</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>USER The washedout idiot Biden feels he has a ...</td>\n",
       "      <td>subtask_a</td>\n",
       "      <td>OFF</td>\n",
       "      <td>Level A: Offensive language identification \\r\\...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>OLID19</td>\n",
       "      <td>USER Fair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4204 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:04:42.063767Z",
     "start_time": "2024-09-14T06:04:42.056768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_values = df_aux.groupby(\"dataset_name\")['label_value'].apply(lambda x: list(x.unique()))\n",
    "unique_values"
   ],
   "id": "5cbe288237b9eb97",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_name\n",
       "OLID19    [OFF, NOT, nan]\n",
       "Name: label_value, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:04:44.135856Z",
     "start_time": "2024-09-14T06:04:44.121844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def map_label_value(row):\n",
    "    if row[\"dataset_name\"] == \"DGHD\":\n",
    "        if row[\"label_value\"] == \"hate\":\n",
    "            return 1\n",
    "    \n",
    "    elif row[\"dataset_name\"] == \"OLID\":\n",
    "        if row[\"label_value\"] == \"OFF\":\n",
    "            return 1\n",
    "    \n",
    "    elif row[\"dataset_name\"] == \"MHS\":\n",
    "        if float(row[\"label_value\"]) > 0.5:\n",
    "            return 1\n",
    "    \n",
    "    elif row[\"dataset_name\"] == \"Ethos\":\n",
    "        if float(row[\"label_value\"]) >= 0.5:\n",
    "            return 1\n",
    "    \n",
    "    return 0"
   ],
   "id": "39adb97e850be469",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:04:05.238157Z",
     "start_time": "2024-09-14T06:04:05.188155Z"
    }
   },
   "cell_type": "code",
   "source": "df_aux[\"label_value\"] = df.apply(map_label_value,axis=1)",
   "id": "3def2422c3e69a2b",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_aux' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdf_aux\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel_value\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mapply(map_label_value,axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_aux' is not defined"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:04:05.815995Z",
     "start_time": "2024-09-14T06:04:05.794979Z"
    }
   },
   "cell_type": "code",
   "source": "df_aux",
   "id": "10eec0726ddab980",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_aux' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdf_aux\u001B[49m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_aux' is not defined"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:03:59.213454Z",
     "start_time": "2024-09-14T06:03:59.195454Z"
    }
   },
   "cell_type": "code",
   "source": "len(df_aux[df_aux[\"label_value\"]==1]) / len(df_aux)",
   "id": "3b52e34b84a78b3b",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_aux' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mlen\u001B[39m(\u001B[43mdf_aux\u001B[49m[df_aux[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel_value\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(df_aux)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_aux' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T06:03:59.730315Z",
     "start_time": "2024-09-14T06:03:59.708324Z"
    }
   },
   "cell_type": "code",
   "source": "len(df_target[df_target[\"label_value\"]==1]) / len(df_target)",
   "id": "fba32a59664dea7e",
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdf_target\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdf_target\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlabel_value\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdf_target\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mZeroDivisionError\u001B[0m: division by zero"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T08:00:38.498840Z",
     "start_time": "2024-09-01T08:00:37.309436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Sampler import balanced_fixedcount\n",
    "\n",
    "aux_train = balanced_fixedcount(df_aux, 100000, \"label_value\", \"dataset_name\")\n",
    "aux_train"
   ],
   "id": "7d6fccaf5c452d19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label second_col\n",
      "0      A          Y\n",
      "1      A          Z\n",
      "2      A          X\n",
      "3      A          Y\n",
      "4      A          Y\n",
      "5      B          Z\n",
      "6      B          X\n",
      "7      B          Z\n",
      "8      B          Z\n",
      "9      B          X\n",
      "10     C          Z\n",
      "11     C          Z\n",
      "12     C          Y\n",
      "13     C          Z\n",
      "14     C          Z\n",
      "  label second_col\n",
      "0     A          X\n",
      "1     A          Z\n",
      "2     A          X\n",
      "3     B          X\n",
      "4     B          Y\n",
      "5     B          Z\n",
      "6     C          Y\n",
      "7     C          Z\n",
      "8     C          Y\n",
      "   label second_col\n",
      "0      C          Y\n",
      "1      C          Z\n",
      "2      A          Y\n",
      "3      C          Y\n",
      "4      B          X\n",
      "5      A          X\n",
      "6      A          Z\n",
      "7      C          X\n",
      "8      B          Z\n",
      "9      B          Z\n",
      "10     A          Y\n",
      "11     B          Z\n",
      "   label second_col\n",
      "0      A          X\n",
      "1      A          X\n",
      "2      A          Y\n",
      "3      A          Y\n",
      "4      A          Z\n",
      "5      A          Z\n",
      "6      B          X\n",
      "7      B          X\n",
      "8      B          Y\n",
      "9      B          Y\n",
      "10     B          Z\n",
      "11     B          Z\n",
      "12     C          X\n",
      "13     C          X\n",
      "14     C          Y\n",
      "15     C          Y\n",
      "16     C          Z\n",
      "17     C          Z\n",
      "  label second_col\n",
      "0     A          X\n",
      "1     A          Y\n",
      "2     A          Z\n",
      "3     B          X\n",
      "4     B          Y\n",
      "5     B          Z\n",
      "6     C          X\n",
      "7     C          Y\n",
      "8     C          Z\n",
      "   label second_col\n",
      "0      A          X\n",
      "1      C          Y\n",
      "2      A          X\n",
      "3      C          Z\n",
      "4      B          Z\n",
      "5      C          Z\n",
      "6      A          Z\n",
      "7      A          Y\n",
      "8      C          Z\n",
      "9      B          Y\n",
      "10     C          Y\n",
      "11     A          X\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      dataset_name                                               text  \\\n",
       "0             DGHD  Young Womens Trust needs to be destroyed or th...   \n",
       "1              MHS  DoingRight1 Why did anyone think allowing hord...   \n",
       "2              MHS                  Life without Allah is meaningless   \n",
       "3             DGHD                     this is a Fucken blaady madlad   \n",
       "4              MHS      Okay rniceguys front man Whos the incel again   \n",
       "...            ...                                                ...   \n",
       "99995          MHS                   libertyladyusa Deport this trash   \n",
       "99996          MHS                                Ha Take that nigger   \n",
       "99997          MHS  Hitler didnt finish it Can u If a nigger ur Je...   \n",
       "99998        Ethos  When lift your arms do your boobs go away They...   \n",
       "99999          MHS  White dude here Feel the same way The dream is...   \n",
       "\n",
       "              label_name  label_value  \\\n",
       "0                  label            0   \n",
       "1      hate_speech_score            1   \n",
       "2      hate_speech_score            0   \n",
       "3                  label            0   \n",
       "4      hate_speech_score            0   \n",
       "...                  ...          ...   \n",
       "99995  hate_speech_score            1   \n",
       "99996  hate_speech_score            0   \n",
       "99997  hate_speech_score            1   \n",
       "99998             isHate            0   \n",
       "99999  hate_speech_score            0   \n",
       "\n",
       "                                        label_definition  \\\n",
       "0      a binary variable, indicating whether or not t...   \n",
       "1      Continuous hate speech measure, where higher =...   \n",
       "2      Continuous hate speech measure, where higher =...   \n",
       "3      a binary variable, indicating whether or not t...   \n",
       "4      Continuous hate speech measure, where higher =...   \n",
       "...                                                  ...   \n",
       "99995  Continuous hate speech measure, where higher =...   \n",
       "99996  Continuous hate speech measure, where higher =...   \n",
       "99997  Continuous hate speech measure, where higher =...   \n",
       "99998                                                NaN   \n",
       "99999  Continuous hate speech measure, where higher =...   \n",
       "\n",
       "                             source language  \n",
       "0                               NaN      eng  \n",
       "1      YouTube, Twitter, and Reddit      eng  \n",
       "2      YouTube, Twitter, and Reddit      eng  \n",
       "3                               NaN      eng  \n",
       "4      YouTube, Twitter, and Reddit      eng  \n",
       "...                             ...      ...  \n",
       "99995  YouTube, Twitter, and Reddit      eng  \n",
       "99996  YouTube, Twitter, and Reddit      eng  \n",
       "99997  YouTube, Twitter, and Reddit      eng  \n",
       "99998                         Multi      eng  \n",
       "99999  YouTube, Twitter, and Reddit      eng  \n",
       "\n",
       "[100000 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>text</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label_value</th>\n",
       "      <th>label_definition</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DGHD</td>\n",
       "      <td>Young Womens Trust needs to be destroyed or th...</td>\n",
       "      <td>label</td>\n",
       "      <td>0</td>\n",
       "      <td>a binary variable, indicating whether or not t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MHS</td>\n",
       "      <td>DoingRight1 Why did anyone think allowing hord...</td>\n",
       "      <td>hate_speech_score</td>\n",
       "      <td>1</td>\n",
       "      <td>Continuous hate speech measure, where higher =...</td>\n",
       "      <td>YouTube, Twitter, and Reddit</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MHS</td>\n",
       "      <td>Life without Allah is meaningless</td>\n",
       "      <td>hate_speech_score</td>\n",
       "      <td>0</td>\n",
       "      <td>Continuous hate speech measure, where higher =...</td>\n",
       "      <td>YouTube, Twitter, and Reddit</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DGHD</td>\n",
       "      <td>this is a Fucken blaady madlad</td>\n",
       "      <td>label</td>\n",
       "      <td>0</td>\n",
       "      <td>a binary variable, indicating whether or not t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MHS</td>\n",
       "      <td>Okay rniceguys front man Whos the incel again</td>\n",
       "      <td>hate_speech_score</td>\n",
       "      <td>0</td>\n",
       "      <td>Continuous hate speech measure, where higher =...</td>\n",
       "      <td>YouTube, Twitter, and Reddit</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>MHS</td>\n",
       "      <td>libertyladyusa Deport this trash</td>\n",
       "      <td>hate_speech_score</td>\n",
       "      <td>1</td>\n",
       "      <td>Continuous hate speech measure, where higher =...</td>\n",
       "      <td>YouTube, Twitter, and Reddit</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>MHS</td>\n",
       "      <td>Ha Take that nigger</td>\n",
       "      <td>hate_speech_score</td>\n",
       "      <td>0</td>\n",
       "      <td>Continuous hate speech measure, where higher =...</td>\n",
       "      <td>YouTube, Twitter, and Reddit</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>MHS</td>\n",
       "      <td>Hitler didnt finish it Can u If a nigger ur Je...</td>\n",
       "      <td>hate_speech_score</td>\n",
       "      <td>1</td>\n",
       "      <td>Continuous hate speech measure, where higher =...</td>\n",
       "      <td>YouTube, Twitter, and Reddit</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Ethos</td>\n",
       "      <td>When lift your arms do your boobs go away They...</td>\n",
       "      <td>isHate</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Multi</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>MHS</td>\n",
       "      <td>White dude here Feel the same way The dream is...</td>\n",
       "      <td>hate_speech_score</td>\n",
       "      <td>0</td>\n",
       "      <td>Continuous hate speech measure, where higher =...</td>\n",
       "      <td>YouTube, Twitter, and Reddit</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T08:00:38.528894Z",
     "start_time": "2024-09-01T08:00:38.499886Z"
    }
   },
   "cell_type": "code",
   "source": "len(aux_train[aux_train[\"label_value\"]==1]) / len(aux_train)",
   "id": "6e22ecd92a35e561",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45541"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Target Split",
   "id": "8e8510da026c78f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T08:00:38.655061Z",
     "start_time": "2024-09-01T08:00:38.530896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_tdf, test_tdf = train_test_split(df_target, test_size=0.2, stratify=df_target['label_value'], random_state=42)"
   ],
   "id": "119b6b8878814a39",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T08:00:38.671071Z",
     "start_time": "2024-09-01T08:00:38.657052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tool.utils.sampling import balanced_downsampling\n",
    "print(\"Before Downsampling: \",len(test_tdf[test_tdf[\"label_value\"]==1]) / len(test_tdf))\n",
    "\n",
    "resampled_test_tdf = balanced_downsampling(test_tdf, \"label_value\")\n",
    "\n",
    "print(\"After Downsampling: \",len(resampled_test_tdf[resampled_test_tdf[\"label_value\"]==1]) / len(resampled_test_tdf))"
   ],
   "id": "477a9ded481bc21a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Downsampling:  0.24275\n",
      "After Downsampling:  0.5\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T08:00:42.073823Z",
     "start_time": "2024-09-01T08:00:40.793993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_tdf.to_csv(\"train_tdf.csv\")\n",
    "test_tdf.to_csv(\"test_tdf.csv\")\n",
    "aux_train.to_csv(\"aux_train.csv\")"
   ],
   "id": "abb1e632440b017a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T08:00:42.968396Z",
     "start_time": "2024-09-01T08:00:42.075775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for train_per in [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    _, train_tdf_slice = train_test_split(train_tdf, test_size = train_per, stratify=train_tdf['label_value'], random_state=42)"
   ],
   "id": "64e4b65320eef02e",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "test_size=1.0 should be either positive and smaller than the number of samples 16000 or a float in the (0, 1) range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [25]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train_per \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;241m0.05\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.15\u001B[39m, \u001B[38;5;241m0.2\u001B[39m, \u001B[38;5;241m0.25\u001B[39m, \u001B[38;5;241m0.3\u001B[39m, \u001B[38;5;241m0.4\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.6\u001B[39m, \u001B[38;5;241m0.7\u001B[39m, \u001B[38;5;241m0.8\u001B[39m, \u001B[38;5;241m0.9\u001B[39m, \u001B[38;5;241m1.0\u001B[39m]:\n\u001B[1;32m----> 2\u001B[0m     _, train_tdf_slice \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_test_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_tdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtrain_per\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstratify\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_tdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlabel_value\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m42\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2420\u001B[0m, in \u001B[0;36mtrain_test_split\u001B[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001B[0m\n\u001B[0;32m   2417\u001B[0m arrays \u001B[38;5;241m=\u001B[39m indexable(\u001B[38;5;241m*\u001B[39marrays)\n\u001B[0;32m   2419\u001B[0m n_samples \u001B[38;5;241m=\u001B[39m _num_samples(arrays[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m-> 2420\u001B[0m n_train, n_test \u001B[38;5;241m=\u001B[39m \u001B[43m_validate_shuffle_split\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2421\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefault_test_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.25\u001B[39;49m\n\u001B[0;32m   2422\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2424\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m shuffle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m   2425\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stratify \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2043\u001B[0m, in \u001B[0;36m_validate_shuffle_split\u001B[1;34m(n_samples, test_size, train_size, default_test_size)\u001B[0m\n\u001B[0;32m   2035\u001B[0m train_size_type \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(train_size)\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mkind\n\u001B[0;32m   2037\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2038\u001B[0m     test_size_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mi\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2039\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (test_size \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m n_samples \u001B[38;5;129;01mor\u001B[39;00m test_size \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m   2040\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m test_size_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2041\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (test_size \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m test_size \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m   2042\u001B[0m ):\n\u001B[1;32m-> 2043\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2044\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_size=\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m should be either positive and smaller\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2045\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m than the number of samples \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m or a float in the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2046\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(0, 1) range\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(test_size, n_samples)\n\u001B[0;32m   2047\u001B[0m     )\n\u001B[0;32m   2049\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2050\u001B[0m     train_size_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mi\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2051\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (train_size \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m n_samples \u001B[38;5;129;01mor\u001B[39;00m train_size \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m   2052\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m train_size_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2053\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (train_size \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m train_size \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m   2054\u001B[0m ):\n\u001B[0;32m   2055\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2056\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_size=\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m should be either positive and smaller\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2057\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m than the number of samples \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m or a float in the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2058\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(0, 1) range\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(train_size, n_samples)\n\u001B[0;32m   2059\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: test_size=1.0 should be either positive and smaller than the number of samples 16000 or a float in the (0, 1) range"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ab781f0b52037578"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
