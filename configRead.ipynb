{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-09T09:23:52.607660700Z",
     "start_time": "2024-05-09T09:23:52.591063100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Manual for the Config fileï¼š\n",
    "- `dataset_file_name`: Please include the **full** file name including the datatype, e.g. data.csv, data.tsv. If the datasets are splitted into different sets, seperate the names with a comma `,`\n",
    "- `dataset_name`: The name of the dataset.\n",
    "- `label_name_definition`: Please write the label name and corresponding definition in a `JSON` format.\n",
    "- `source`: For data with a single source, please state the source name, e.g. Twitter, Facebook, etc. Add an `@` symbol in-front, e.g. *@Twitter*. If of multi-source, please provide a column name.\n",
    "- `language`: For single language, language code as stipulated in ISO 639-2 are recognized, e.g. eng, spa, chi, ger, fre, ita, etc (). Add an `@` symbol in-front, e.g. *@eng*. For multi-language contents, please provide a column name describing this property, e.g. languages.\n",
    "- `text`: The column name of text.\n",
    "\n",
    "**Note**:\n",
    "1. Only datasets that are in CSV(comma-seperated) or TSV formats are supported.\n",
    "2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utils"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def strip_comma_from_text_list(orig_list):\n",
    "    res = []\n",
    "    for val in orig_list:\n",
    "        if ',' in val:\n",
    "            # Split the string by comma\n",
    "            strip_list = [item.strip() for item in val.split(',') if item.strip()]\n",
    "            res = res + strip_list\n",
    "        else:\n",
    "            # If no commas, keep the string as is\n",
    "            res.append(val)\n",
    "\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T09:55:49.527770400Z",
     "start_time": "2024-05-09T09:55:49.522195800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def is_columns_in_datasets(df, col_list):\n",
    "    cols_not_in_dataset = list(set(col_list) - set(df.columns))\n",
    "    assert len(cols_not_in_dataset) == 0, f\"In the list provided, {cols_not_in_dataset} are not found in the given dataset\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_dataframe(file_path):\n",
    "    \"\"\"\n",
    "    Read a DataFrame from a CSV or TSV file.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the file.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: DataFrame containing the data from the file.\n",
    "    \"\"\"\n",
    "    if file_path.endswith('.csv'):\n",
    "        # Read CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.tsv'):\n",
    "        # Read TSV file\n",
    "        df = pd.read_csv(file_path, sep='\\t')\n",
    "    else:\n",
    "        # Unsupported file type\n",
    "        raise ValueError(\"Unsupported file type. Only CSV and TSV files are supported.\")\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### General Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "                             dataset_file_name dataset_name  \\\n0                       olid-training-v1.0.tsv       OLID19   \n1  SBFv2.dev.csv, SBFv2.trn.csv, SBFv2.tst.csv        SBFv2   \n\n                               label_name_definition    source language   text  \n0  {\"subtask_a\": \"Level A: Offensive language ide...  @Twitter     @eng  tweet  \n1  {\"intentYN\":\"\", \"sexYN\":\"\", \"sexReason\":\"\", \"o...  @Twitter     @eng   post  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset_file_name</th>\n      <th>dataset_name</th>\n      <th>label_name_definition</th>\n      <th>source</th>\n      <th>language</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>olid-training-v1.0.tsv</td>\n      <td>OLID19</td>\n      <td>{\"subtask_a\": \"Level A: Offensive language ide...</td>\n      <td>@Twitter</td>\n      <td>@eng</td>\n      <td>tweet</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SBFv2.dev.csv, SBFv2.trn.csv, SBFv2.tst.csv</td>\n      <td>SBFv2</td>\n      <td>{\"intentYN\":\"\", \"sexYN\":\"\", \"sexReason\":\"\", \"o...</td>\n      <td>@Twitter</td>\n      <td>@eng</td>\n      <td>post</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_config =  pd.read_csv(\"config.csv\", sep=';',encoding= \"utf-8\").apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "df_config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T09:56:34.409045Z",
     "start_time": "2024-05-09T09:56:34.395533900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "['olid-training-v1.0.tsv', 'SBFv2.dev.csv', 'SBFv2.trn.csv', 'SBFv2.tst.csv']"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = \"./data\"\n",
    "folder_path_file_names = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "folder_path_file_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T09:56:35.339052800Z",
     "start_time": "2024-05-09T09:56:35.330953200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "['olid-training-v1.0.tsv', 'SBFv2.dev.csv', 'SBFv2.trn.csv', 'SBFv2.tst.csv']"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file_name_value = df_config.dataset_file_name.tolist()\n",
    "\n",
    "config_file_names =  strip_comma_from_text_list(config_file_name_value)\n",
    "config_file_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T09:56:36.193522500Z",
     "start_time": "2024-05-09T09:56:36.185366900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename integrity check complete!\n"
     ]
    }
   ],
   "source": [
    "assert len(config_file_names) <= len(folder_path_file_names), f\"Number of datasets listed in Config ({len(config_file_names)}) exceeds that in the folder {len(df_config)}.\"\n",
    "\n",
    "difference_datasets = set(config_file_names) - set(folder_path_file_names)\n",
    "assert len(difference_datasets) == 0, f\"Dataset(s) {difference_datasets} not found in 'data' folder\"\n",
    "df_config.label_name_definition = df_config.label_name_definition.apply(lambda x: json.loads(x))\n",
    "print(\"Filename integrity check complete!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:02:23.679702200Z",
     "start_time": "2024-05-09T10:02:23.668169200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Row-specific Operation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subtask_a', 'subtask_b', 'subtask_c', 'tweet']\n",
      "['intentYN', 'sexYN', 'sexReason', 'offensiveYN', 'post']\n",
      "['intentYN', 'sexYN', 'sexReason', 'offensiveYN', 'post']\n",
      "['intentYN', 'sexYN', 'sexReason', 'offensiveYN', 'post']\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df_config.iterrows():\n",
    "    datasets = strip_comma_from_text_list([row.dataset_file_name])\n",
    "    for dataset in datasets:\n",
    "        df = read_dataframe(folder_path + '/' + dataset)\n",
    "        col_list = list(row.label_name_definition.keys()) + [row.text]\n",
    "        if row.language.startswith('@') == False:\n",
    "            col_list.append(row.language)\n",
    "        if row.source.startswith('@') == False:\n",
    "            col_list.append(row.source)\n",
    "\n",
    "        print(col_list)\n",
    "        is_columns_in_datasets(df, col_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:02:43.017339800Z",
     "start_time": "2024-05-09T10:02:42.608746100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
