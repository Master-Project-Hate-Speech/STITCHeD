dataset_file_name,dataset_name,label_name_definition,source,language,text,
olid-training-v1.0.tsv,OLID19,"{""subtask_a"": ""Level A: Offensive language identification \n- (NOT) Not Offensive - This post does not contain offense or profanity. \n- (OFF) Offensive - This post contains offensive language or a targeted (veiled or direct) offense \n In our annotation, we label a post as offensive (OFF) if it contains any form of non-acceptable language (profanity) or a targeted offense, which can be veiled or direct. "", ""subtask_b"": ""Level B: Automatic categorization of offense types - (TIN) Targeted Insult and Threats - A post containing an insult or threat to an individual, a group, or others (see categories in sub-task C). \n- (UNT) Untargeted - A post containing non-targeted profanity and swearing. \n Posts containing general profanity are not targeted, but they contain non-acceptable language."", ""subtask_c"":""Level C: Offense target identification \n- (IND) Individual - The target of the offensive post is an individual: a famous person, a named individual or an unnamed person interacting in the conversation. \n - (GRP) Group - The target of the offensive post is a group of people considered as a unity due to the same ethnicity, gender or sexual orientation, political affiliation, religious belief, or something else.\n - (OTH) Other ? ? The target of the offensive post does not belong to any of the previous two categories (e.g., an organization, a situation, an event, or an issue)""}",@Twitter,@eng,tweet,
SBFv2.dev.csv;SBFv2.trn.csv;SBFv2.tst.csv,SBFv2,"{""intentYN"":"""", ""sexYN"":"""", ""sexReason"":"""", ""offensiveYN"":""""}",@Twitter,@eng,post,
Dynamically Generated Hate Dataset v0.2.3.csv,DGHD,"{""label"": ""a binary variable, indicating whether or not the content has been identified as hateful. It takes two values: hate, nothate."",""type"":""a categorical variable, providing a secondary label for hateful content. For hate it can take five values: Animosity, Derogation, Dehumanization, Threatening and Support for Hateful Entities. Please see the paper for more detail. For nothate the 'type' is 'none'. In round 1 the 'type' was not given and is marked as 'notgiven'""}",@N/A,@eng,text,
measuring-hate-speech.csv,MHS,"{""hate_speech_score"": ""Continuous hate speech measure, where higher = more hateful and lower = less hateful. > 0.5 is approximately hate speech, < -1 is counter or supportive speech, and -1 to +0.5 is neutral or ambiguous ""} ","@YouTube, Twitter, and Reddit",@eng,text,
GrimmingerKlingerWASSA2021_train.tsv;GrimmingerKlingerWASSA2021_test.tsv ,USElection2020,{"HOF": "if tweet text is hateful and offensive(Hateful) or neither hateful nor offensive(NonHateful)"},@Twitter,@eng,text,
ghc_train.tsv;ghc_test.tsv,GHC,"{""hd"": ""assaults on human dignity"",""cv"": ""Calls for violence"",""vo"": ""Vulgarity and/or Offensive language""} ",@gab.ai,@eng,text,
hs_AsianPrejudice_20kdataset_cleaned_anonymized.tsv,AsianPrejudice ,"{""hostile.threatening"":"""",""hostile.interpersonal"":"""",""COVID relevant"":"""",""EA relevant"":"""",""hashtags.decision"":"""",""East Asia"":"""",""China"":"""",""Hong Kong"":"""",""Japan"":"""",""Korea"":"""",""Singapore"":"""",""Taiwan"":""""}",@Twitter,@eng,text,
Ethos_merged.csv,Ethos,"{""isHate"":"""",""violence"":"""", ""directed_vs_generalized"":"""", ""gender"":"""", ""race"":"""", ""national_origin"":"""", ""disability"":"""", ""religion"":"""", ""sexual_orientation"":""""}",@Multi,@eng,comment,
edos_labelled_aggregated.csv,EDOS,"{""label_sexist"":""TASK A - Binary Sexism Detection: a two-class (or binary) classification where systems have to predict whether a post is sexist or not sexist."",""label_category"":""TASK B - Category of Sexism: for posts which are sexist, a four-class classification where systems have to predict one of four categories: (1) threats, (2)  derogation, (3) animosity, (4) prejudiced discussion."",""label_vector"":""TASK C - Fine-grained Vector of Sexism: for posts which are sexist, an 11-class classification where systems have to predict one of 11 fine-grained vectors."" }","@Gab, @Reddit ",@eng,text,
DIALOCONAN.csv,DIALOCONAN,"{""TARGET"": ""cover 6 main targets of hate, namely JEWS, LGBT+, MIGRANTS, MUSLIMS, PEOPLE OF COLOR (POC), WOMEN"",""type"": ""whether the turn is an HS or a CN""} ",source,@eng,text,
labeled_data.csv ,hate-speech-and-offensive-language,{"class": "the class that the text has been classisfied"} ,@Twitter,@eng,tweet,
train.csv,CivilComments ,"{""target"":""prediction target - toxicity"",""severe_toxicity"": ""subtype"",""obscene"": ""subtype"",""identity_attack"": ""subtype"",""insult"": ""subtype"",""threat"": ""subtype"", ""sexual_explicit"":""subtype"",""female"": ""Identity mentioned in the comment"",""male"": ""Identity mentioned in the comment"",""transgender"": ""Identity mentioned in the comment"",""other_gender"": ""Identity mentioned in the comment"",""heterosexual"": ""Identity mentioned in the comment"",""homosexual_gay_or_lesbian"": ""Identity mentioned in the comment"",""bisexual"": ""Identity mentioned in the comment"",""other_sexual_orientation"": ""Identity mentioned in the comment"",""christian"": ""Identity mentioned in the comment"",""jewish"": ""Identity mentioned in the comment"",""muslim"": ""Identity mentioned in the comment"",""hindu"": ""Identity mentioned in the comment"",""buddhist"": ""Identity mentioned in the comment"",""atheist"": ""Identity mentioned in the comment"",""other_religion"": ""Identity mentioned in the comment"",""black"": ""Identity mentioned in the comment"",""white"": ""Identity mentioned in the comment"",""asian"": ""Identity mentioned in the comment"",""latino"": ""Identity mentioned in the comment"",""other_race_or_ethnicity"": ""Identity mentioned in the comment"",""physical_disability"": ""Identity mentioned in the comment"",""intellectual_or_learning_disability"": ""Identity mentioned in the comment"",""psychiatric_or_mental_illness"": ""Identity mentioned in the comment"",""other_disability"": ""Identity mentioned in the comment""}",@Civil Comments,@eng,comment_text, 
