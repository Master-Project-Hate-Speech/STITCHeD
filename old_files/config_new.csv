dataset_file_name,dataset_name,label_name_definition,source,language,text
olid-training-v1.0.tsv,OLID19,"{""subtask_a"": ""Level A: Offensive language identification \n- (NOT) Not Offensive - This post does not contain offense or profanity. \n- (OFF) Offensive - This post contains offensive language or a targeted (veiled or direct) offense \n In our annotation, we label a post as offensive (OFF) if it contains any form of non-acceptable language (profanity) or a targeted offense, which can be veiled or direct. "", ""subtask_b"": ""Level B: Automatic categorization of offense types - (TIN) Targeted Insult and Threats - A post containing an insult or threat to an individual, a group, or others (see categories in sub-task C). \n- (UNT) Untargeted - A post containing non-targeted profanity and swearing. \n Posts containing general profanity are not targeted, but they contain non-acceptable language."", ""subtask_c"":""Level C: Offense target identification \n- (IND) Individual - The target of the offensive post is an individual: a famous person, a named individual or an unnamed person interacting in the conversation. \n - (GRP) Group - The target of the offensive post is a group of people considered as a unity due to the same ethnicity, gender or sexual orientation, political affiliation, religious belief, or something else.\n - (OTH) Other ? ? The target of the offensive post does not belong to any of the previous two categories (e.g., an organization, a situation, an event, or an issue)""}",@Twitter,@eng,tweet
SBFv2.dev.csv;SBFv2.trn.csv;SBFv2.tst.csv,SBFv2,"{""intentYN"":"""", ""sexYN"":"""", ""sexReason"":"""", ""offensiveYN"":""""}",@Twitter,@eng,post
Dynamically Generated Hate Dataset v0.2.3.csv,DGHD,"{""label"": ""a binary variable, indicating whether or not the content has been identified as hateful. It takes two values: hate, nothate."",""type"":""a categorical variable, providing a secondary label for hateful content. For hate it can take five values: Animosity, Derogation, Dehumanization, Threatening and Support for Hateful Entities. Please see the paper for more detail. For nothate the 'type' is 'none'. In round 1 the 'type' was not given and is marked as 'notgiven'""}",@N/A,@eng,text
measuring-hate-speech.csv,MHS,"{""hate_speech_score"": ""Continuous hate speech measure, where higher = more hateful and lower = less hateful. > 0.5 is approximately hate speech, < -1 is counter or supportive speech, and -1 to +0.5 is neutral or ambiguous ""} ","@YouTube, Twitter, and Reddit",@eng,text
GrimmingerKlingerWASSA2021_train.tsv;GrimmingerKlingerWASSA2021_test.tsv ,USElection2020,{"HOF": "if tweet text is hateful and offensive(Hateful) or neither hateful nor offensive(NonHateful)"},@Twitter,@eng,text
ghc_train.tsv;ghc_test.tsv,GHC,"{""hd"": ""assaults on human dignity"",""cv"": ""Calls for violence"",""vo"": ""Vulgarity and/or Offensive language""} ",@gab.ai,@eng,text
hs_AsianPrejudice_20kdataset_cleaned_anonymized.tsv,AsianPrejudice ,"{""hostile.threatening"":"""",""hostile.interpersonal"":"""",""COVID relevant"":"""",""EA relevant"":"""",""hashtags.decision"":"""",""East Asia"":"""",""China"":"""",""Hong Kong"":"""",""Japan"":"""",""Korea"":"""",""Singapore"":"""",""Taiwan"":""""}",@Twitter,@eng,text
Ethos_merged.csv,Ethos,"{""isHate"":"""",""violence"":"""", ""directed_vs_generalized"":"""", ""gender"":"""", ""race"":"""", ""national_origin"":"""", ""disability"":"""", ""religion"":"""", ""sexual_orientation"":""""}",@Multi,@eng,comment
edos_labelled_aggregated.csv,EDOS,"{""label_sexist"":""TASK A - Binary Sexism Detection: a two-class (or binary) classification where systems have to predict whether a post is sexist or not sexist."",""label_category"":""TASK B - Category of Sexism: for posts which are sexist, a four-class classification where systems have to predict one of four categories: (1) threats, (2)  derogation, (3) animosity, (4) prejudiced discussion."",""label_vector"":""TASK C - Fine-grained Vector of Sexism: for posts which are sexist, an 11-class classification where systems have to predict one of 11 fine-grained vectors."" }","@Gab, @Reddit ",@eng,text
DIALOCONAN.csv,DIALOCONAN,"{""TARGET"": ""cover 6 main targets of hate, namely JEWS, LGBT+, MIGRANTS, MUSLIMS, PEOPLE OF COLOR (POC), WOMEN"",""type"": ""whether the turn is an HS or a CN""} ",source,@eng,text
ar_dataset.csv;en_dataset.csv;fr_dataset.csv,MLMA02,{"sentiment": "the hostility type of the tweet"},@Twitter,language,tweet
labeled_data.csv ,hate-speech-and-offensive-language,{"class": "the class that the text has been classisfied"} ,@Twitter,@eng,tweet
MLMA.csv,MLMA,"{""sentiment"":""To identify the hostility type of the tweet, we stick to the following conventions: (1) if the tweet sounds dangerous, it should be la beled as abusive; (2) according to the degree to which it spreads hate and the tone its author uses, it can be hateful, offensive or disrespectful; (3) if the tweet expresses or spreads fear out of ignorance against a group of individuals, it should be labeled as fearful; (4) otherwise it should be annotated as normal. We define this task to be multilabel.""}",@Twitter,@ara,tweet
annotated-hatetweets-4-classes_train.csv;annotated-hatetweets-4-classes_test.csv,JHSC,"{""Label"":""the dataset has 4 labels: a. Negative: No hate speech is included in the tweet. b. Neutral: General tweet (add, prayer, no sentiment is included) c. Positive: A hate speech exists, bullying, sarcasm, racism, ...etc. d. Very positive: A severe hate speech exists; includes phrases that can cause fights, or very bad influence on people and society.""}",@Twitter,@ara,new_tweet_content
IDHSD_RIO_unbalanced_713_2017.csv,IDHSD,{"Label":"Non_HS for non-hate-speech HS for hate speech"},@Twitter,@ind,Tweet
re_dataset.csv,id-multi-label-hate-speech-and-abusive-language,"{""HS"": ""hate speech label, with 1 for yes and 0 for no"", ""Abusive"": ""abusive speech label, with 1 for yes and 0 for no""}",@Twitter,@ind,Tweet
572-hate-speech-dataset.csv,HS_Indonesian_Insta_Comments,{"class": "hate speech(HS) or not hate speech (Non_HS)"},@Ins,@ind,comment_text
TNS.csv,TNS,{"Etiket": ""}, @Twitter,@tur,Tweet
hs_AsianPrejudice_20kdataset_cleaned_anonymized.tsv,EAP,{"expert": ""},@Twitter,@eng,text.clean
HatemojiBuild_train.csv;HatemojiBuild_test.csv;HatemojiBuild_validation.csv,HatemojiBuild,"{""label_gold"": ""The gold standard label (hateful/non-hateful) of the test case."", ""type"": ""The type of hate assigned to hateful entries.""}",@Dynabench,@eng,text
HateNet_labeled.csv,HateNet,{"hateful": "hateful/non-hateful"},@Twitter,@spa,text
fox-comment.csv,fox-comment,{"hateful": "hateful/non-hateful"},@FoxNews,@eng,text
hascosva_2022_anonymized.tsv,HaSCoSVa,{"label": "hateful/non-hateful"},@Twitter,@spa,text
RP-Mod.csv,RP-Mod,{"label": ""} ,@Rheinische Post,@ger,text
german hatespeech refugees.csv,IWG_hatespeech_public,{"HatespeechOrNot (Aggregated)": ""},@Twitter,@ger,Tweet
gahd.csv,GAHD,"{""label"": ""0 = not-hate speech, 1 = hate speech""} ",@Multi,@ger,text
german_dataset.tsv;hasoc_de_test_gold.tsv,HASOC2019_DE,"{""task_1"":""Hate and Offensive (HOF) and Non- Hate and offensive (NOT)"", ""task_2"":""(HATE) Hate speech - Posts under this class contain Hate speech content,(OFFN) Offenive - Posts under this class contain offensive content, (PRFN) Profane - These posts contain profane words""} ",@Twitter and Facebook,@ger,text
